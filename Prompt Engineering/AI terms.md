## AI Hallucination
An AI hallucination is when a large language model (LLM) generates false information. To avoid AI hallucinations there are several techniques. Discussed in 
[[Methods of Prompt Engineering]]
## Text Embedding
Text embedding is a popular technique to represent textual information in a format that can be easily processed by algorithms, especially deep learning models. Text data is converted into the large array of numbers can say integers.
